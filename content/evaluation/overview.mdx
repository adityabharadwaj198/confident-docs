---
title: Overview
---

import { Callout, Cards } from "nextra/components";

# Evaluation Overview

Confident AI's evaluation features are second-to-none, and in fact all features you've seen up to this point in the documentation leads up to the LLM evaluation suite.

## Features Summary

<Cards>
  <Cards.Card arrow title="Metrics" href="/evaluation/metrics" />
  <Cards.Card
    arrow
    title="Running Evals"
    href="/evaluation/running-llm-evals"
  />
  <Cards.Card
    arrow
    title="Unit-Testing in CI/CD"
    href="/evaluation/unit-testing-in-cicd"
  />
  <Cards.Card
    arrow
    title="Testing Reports"
    href="/evaluation/testing-reports"
  />
  <Cards.Card
    arrow
    title="A|B Regression Testing"
    href="/evaluation/ab-regression-testing"
  />
  <Cards.Card arrow title="Insights" href="/evaluation/insights" />
</Cards>

## Simple Walkthrough

### Implement Metrics

### Prepare for Evaluation

#### Pull dataset

#### Pull prompt version

### Run an LLM Eval

### Identify Failing Test Case(s)

### Improve LLM app

### Run Another LLM Eval

### Regression Test Your App

### Drawing A|B Insights

## Future Roadmap

- [ ] Insights page
- [ ] Better hyperparameters display
- [ ] Editor table columns for custom metrics
