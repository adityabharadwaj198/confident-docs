---
title: OpenAI Agents
---

import { Callout } from "nextra/components";

# OpenAI Agents

[OpenAI Agents](https://github.com/openai/openai-agents-python) is a lightweight framework for creating agentic workflows using agent swarms, handoffs, and tool use. Confident AI also allows you to trace OpenAI Agent workflows with one line of code.

## Quickstart

Install deepeval:

```bash
pip install -U deepeval
```

Login using your API key on Confident AI in the CLI:

```bash
deepeval login --confident-api-key YOUR_API_KEY
```

Trace your OpenAI Agent workflows:

```python showLineNumbers {4}
from agents import Agent, Runner, add_trace_processor
from deepeval.openai_agents import DeepEvalTracingProcessor

add_trace_processor(DeepEvalTracingProcessor())

# Replace with your agent code
agent = Agent(name="Assistant", instructions="You are a helpful assistant")
result = Runner.run_sync(agent, "Write a haiku about recursion in programming.")
print(result.final_output)
```


<VideoDisplayer
  src="https://confident-docs.s3.us-east-1.amazonaws.com/llm-tracing:integrations:openai-agents.mp4"
  width="100%"
  title="Tracing OpenAI Agent Example"
/>


Confident AI's `DeepEvalTracingProcessor` automatically traces the following span types:


- `AgentSpanData`: OpenAI span for agents 
- `FunctionSpanData`: OpenAI span for function calls 
- `MCPListToolsSpanData`: OpenAI span for MCP tool calls 
- `GenerationSpanData`: OpenAI span for LLM chat completions  
- `ResponseSpanData`: OpenAI span for LLM response creations 
- `HandoffSpanData`: OpenAI span for agent handoffs 
- `GuardrailSpanData`: OpenAI span for guardrails triggered 

## Streaming Responses

<Callout type="info">
`DeepEvalTracingProcessor` handles both asynchronous workflows and streamed responses.  
</Callout>

The code example below shows how to as trace asynchronous calls to an agent that streams responses.

```python showLineNumbers {6,13}
from deepeval.openai_agents import DeepEvalTracingProcessor
from openai.types.responses import ResponseTextDeltaEvent
from agents import Agent, Runner, add_trace_processor
import asyncio

add_trace_processor(DeepEvalTracingProcessor())

async def streaming_agent():
    agent = Agent(
        name="Joker",
        instructions="You are a helpful assistant.",
    )
    result = Runner.run_streamed(agent, input="Please tell me 5 jokes.")
    async for event in result.stream_events():
        if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
            print(event.data.delta, end="", flush=True)

async def main():
    tasks = [streaming_agent() for _ in range(5)]
    await asyncio.gather(*tasks)

asyncio.run(main())
```

## Logging Threads

Chat conversation threads are also automatically logged to Confident AI when a `group_id` is provided in your OpenAI Agent workflow.

```python showLineNumbers {4}
from agents import Agent, Runner, trace, add_trace_processor
from deepeval.openai_agents import DeepEvalTracingProcessor
 
add_trace_processor(DeepEvalTracingProcessor())

thread_id = "unique_thread_id"

async def main():
    agent = Agent(name="Assistant", instructions="Reply very concisely.")

    with trace(workflow_name="Conversation", group_id=thread_id):
        # First turn
        result = await Runner.run(agent, "What city is the Golden Gate Bridge in?")
        print(result.final_output)
        # San Francisco

        # Second turn
        new_input = result.to_input_list() + [{"role": "user", "content": "What state is it in?"}]
        result = await Runner.run(agent, new_input)
        print(result.final_output)
        # California
```
