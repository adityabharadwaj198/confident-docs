---
title: Opentelemetry
---
import { Callout } from "nextra/components";

# Opentelemetry Span Exporter

Confidential AI integrates with OpenTelemetry that allows teams to export traces to the **[Observatory](https://documentation.confident-ai.com/llm-observability/overview)** via a Span Exporter.

<Callout>
  A [trace](https://opentelemetry.io/docs/concepts/signals/traces/) is a collection of **spans**, which are the basic unit of work in OpenTelemetry.
</Callout>

## Quick Start
Setup the Opentelemetry tracer to export traces to the Observatory. We encourage the use of `BatchSpanProcessor` to export traces for performance reasons.

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

import deepeval
from deepeval.tracing.otel.exporter import ConfidentSpanExporter
from keys import CONFIDENT_API_KEY

# Setup OpenTelemetry tracer - handle existing TracerProvider
if not isinstance(trace.get_tracer_provider(), TracerProvider):
    tracer_provider = TracerProvider()
    trace.set_tracer_provider(tracer_provider)
else:
    tracer_provider = trace.get_tracer_provider()

deepeval.login_with_confident_api_key(CONFIDENT_API_KEY)

# Create confident span exporter
exporter = ConfidentSpanExporter()

span_processor = BatchSpanProcessor(exporter)
tracer_provider.add_span_processor(span_processor)
tracer = trace.get_tracer("test_tracer")
```


<Callout>
  ConfidentExporter accepts any span that adheres to the [OpenTelemetry specification](https://opentelemetry.io/docs/concepts/signals/traces/). We encourage the use of [Semantic conventions for generative AI systems](https://opentelemetry.io/docs/specs/semconv/gen-ai/) to ensure that the spans are compatible with the Confidential AI Observability Platform.
</Callout>

### LLM Attributes
Confidential AI supports the following LLM operations:
- `chat`
- `text_completion`
- `generate_content`

```python showLineNumbers
with tracer.start_as_current_span("chat gpt-4o") as parent_span:
    
    parent_span.set_attribute("gen_ai.operation.name", "chat")  # can be chat, text_completion, generate_content

    # set model, usage, and cost per token
    parent_span.set_attribute("gen_ai.request.model", "gpt-4o")
    parent_span.set_attribute("gen_ai.usage.input_tokens", 10)
    parent_span.set_attribute("gen_ai.usage.output_tokens", 20)
    parent_span.set_attribute("confident.llm.cost_per_input_token", 0.0001)
    parent_span.set_attribute("confident.llm.cost_per_output_token", 0.0002)

    # input messages will be events in the span
    parent_span.add_event("gen_ai.system.message", {"content": "you are a helpful assistant"})
    parent_span.add_event("gen_ai.user.message", {"content": "What is the capital of France?"})

    # output should be a single event per llmspan
    parent_span.add_event("gen_ai.assistant.message", {"content": "The capital of France is Paris."})  # can be gen_ai.assistant.message, gen_ai.choice, gen_ai.tool.message
```

The following table shows the properties that are mapped to [LLM spans](https://documentation.confident-ai.com/llm-tracing/tracing-features/attributes#llm-attributes) in Confident AI attributes.

|Confident AI Attribute| Property | Type |
|----------|---------|--------|
`model` | `gen_ai.request.model` | Attribute | 
`input_tokens` | `gen_ai.usage.input_tokens` | Attribute |
`output_tokens` | `gen_ai.usage.output_tokens` | Attribute |
`cost_per_input_token` | `confident.llm.cost_per_input_token` | Attribute |
`cost_per_output_token` | `confident.llm.cost_per_output_token` | Attribute |
`input` |`gen_ai.system.message` `gen_ai.user.message`| Event | 
`output` |`gen_ai.assistant.message` `gen_ai.choice` `gen_ai.tool.message`| Event | 


### Tool Attributes
Confidential AI supports the following tool operations:
- `execute_tool`
- `invoke_agent`

```python showLineNumbers
with tracer.start_as_current_span("execute_tool example_tool") as tool_span:
    # set tool name and description
    tool_span.set_attribute("gen_ai.operation.name", "execute_tool")
    tool_span.set_attribute("gen_ai.tool.description", "example_tool_description")

    # input and output must be a single event per toolspan
    tool_span.add_event("confident.tool.input", {"temp": "example_tool_input"})
    tool_span.add_event("confident.tool.output", {"temp": "example_tool_output"})
```

The following table shows the properties that are mapped to [Tool spans](https://documentation.confident-ai.com/llm-tracing/tracing-features/attributes#tool-attributes) in Confident AI attributes.

| Confident AI Attribute | Property | Type |
|----------|---------|--------|
| `description` | `gen_ai.tool.description` | Attribute |
| `input_parameters` | `confident.tool.input` | Event |
| `output` | `confident.tool.output` | Event |

### Agent Attributes
Confidential AI supports the following agent operations:
- `create_agent`
- `invoke_agent`

```python showLineNumbers
with tracer.start_as_current_span("create_agent example_agent") as agent_span:
    
    agent_span.set_attribute("gen_ai.operation.name", "create_agent")  # can be create_agent or invoke_agent
    agent_span.set_attribute("gen_ai.agent.description", "example_agent_description")

    # set available tools and handoffs
    agent_span.set_attribute("confident.agent.available_tools", ["example_tool"])  # should be list of tool names
    agent_span.set_attribute("confident.agent.agent_handoffs", ["example_handoff"])  # should be list of handoff names

    # input and output must be a single event per agent span
    agent_span.add_event("confident.agent.input", {"input": "example_input"})
    agent_span.add_event( "confident.agent.output", {"output": "example_output"})
```


The following table shows the properties that are mapped to [Agent spans](https://documentation.confident-ai.com/llm-tracing/tracing-features/attributes#agent-attributes) in Confident AI attributes.

| Confident AI Attribute | Property | Type |
|----------|---------|--------|
| `available_tools` | `confident.agent.available_tools` | Attribute |
| `agent_handoffs` | `confident.agent.agent_handoffs` | Attribute |
| `input` | `confident.agent.input` | Event |
| `output` | `confident.agent.output` | Event |


### Retriever Attributes
Confidential AI supports the following retriever operations:
- `embeddings`
- `retrieve`

```python showLineNumbers
with tracer.start_as_current_span("embeddings openai_ada") as retriever_span:
    # set name, model, top_k, and chunk_size
    retriever_span.set_attribute("gen_ai.operation.name", "embeddings")
    retriever_span.set_attribute("gen_ai.request.model", "openai_ada")
    retriever_span.set_attribute("confident.retriever.top_k", 10)
    retriever_span.set_attribute("confident.retriever.chunk_size", 100)

    # input and output must be a single event per retriever span
    retriever_span.add_event("confident.retriever.input", {"input": "example_input"})
    retriever_span.add_event("confident.retriever.output", {"output": "example_output"})
```

The following table shows the properties that are mapped to [Retriever spans](https://documentation.confident-ai.com/llm-tracing/tracing-features/attributes#retriever-attributes) in Confident AI attributes.

| Confident AI Attribute | Property | Type |
|----------|---------|--------|
| `embedder` | `gen_ai.request.model` | Attribute |
| `top_k` | `confident.retriever.top_k` | Attribute |
| `chunk_size` | `confident.retriever.chunk_size` | Attribute |
| `embedding_input` | `confident.retriever.input` | Event |
| `retrieval_context` | `confident.retriever.output` | Event |

### Nested spans

The Opentelemetry tracer supports nested spans. Nested spans appear as a child of the parent span in the Observatory.
```python showLineNumbers
with tracer.start_as_current_span("chat gpt-4o") as parent_span:
    parent_span.set_attribute("gen_ai.operation.name", "generate_content")
    parent_span.set_attribute("gen_ai.request.model", "gpt-4o")

    parent_span.add_event("gen_ai.system.message", {"content": "you are a helpful assistant"})
    parent_span.add_event("gen_ai.user.message", {"content": "What is the capital of France?"})

    with tracer.start_as_current_span("execute_tool example_tool") as tool_span:
        tool_span.set_attribute("gen_ai.operation.name", "execute_tool")
        tool_span.set_attribute("gen_ai.tool.description", "example_tool_description")

        tool_span.add_event("confident.tool.input", {"temp": "example_tool_input"})
        tool_span.add_event("confident.tool.output", {"temp": "example_tool_output"})
```

<Callout>
  All the OpenTelemetry span's attributes and events are available in the Confident `metadata` property as a fallback.
</Callout>


