---
title: Create Metrics
---

import { Callout } from "nextra/components";

# Creating Custom Metrics via Evals API

All metrics you create a by definition **custom metrics**. Default metrics, which are all DeepEval metrics, are available to be added to any metric collection anytime.

## Create Metric(s)

Your metric `name` and `multiturn` combination **MUST BE UNIQUE** within a project.

### Single-turn

Also know as a "G-Eval" metric (a custom single-turn metric offered by DeepEval), the request body should be **strictly** the an object of `"metrics"` to a list of [`Metric` data models](/api/metrics/data-model#metric), but additionally requiring either the `criteria` and/or `evaluationSteps`, and `evaluationParams`:

```bash filename="POST - /v1/metrics" showLineNumbers {10}
curl -X POST "https://api.confident-ai.com/v1/metrics" \
     -H "Content-Type: application/json" \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -d '{
            "metrics": [
                {            
                    "name": "Correctness",
                    "criteria": "Determine if the 'actual output' is correct based on the 'expected output'.",
                    "evaluationParams": ["actualOutput", "expectedOutput"],
                    "multiturn": false
                }
            ]
         }`
```

```json filename="response" showLineNumbers
{
  "success": true,
  "data": {"metricIds": ["TODO"]}
}
```

<Callout>All custom metrics uses [DeepEval's G-Eval](https://deepeval.com/docs/metrics-llm-evals) implementation. You should learn more about it to learn what a good `criteria`, `evaluationSteps`, and `evaluationParams` looks like.</Callout>

### Multi-turn

Also known as a "Conversational G-Eval" metric (a multi-turn custom metric offered by DeepEval), the request body should be **strictly** the an object of `"metrics"` to a list of [`Metric` data models](/api/metrics/data-model#metric), but additionally requiring either the `criteria` and/or `evaluationSteps`:

```bash filename="POST - /v1/metrics" showLineNumbers {9}
curl -X POST "https://api.confident-ai.com/v1/metrics" \
     -H "Content-Type: application/json" \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -d '{
            "metrics": [
                {            
                    "name": "Relevancy",
                    "criteria": "Determine if the assistant answers are relevant to what the user is asking.",
                    "multiturn": true
                }
            ]
         }`
```

```json filename="response" showLineNumbers
{
  "success": true,
  "data": {"metricIds": ["TODO"]}
}
```

You **don't** have to provide `evaluationParams` when creating a multi-turn, conversational metric.

## Update Metric

The request body should be **strictly** the [`Metric` data model](/api/metrics/data-model#metric), but additionally it is required that after updating either the `criteria` and/or `evaluationSteps`, and `evaluationParams` still has to be populated:

```bash filename="PUT - /v1/metrics/:id" showLineNumbers
curl -X PUT "https://api.confident-ai.com/v1/metrics/:id" \
     -H "Content-Type: application/json" \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>" \
     -d '{
            "metricId": "TODO",
            "criteria": "Determine if the 'actual output' is correct based on the 'input'.",
            "evaluationParams": ["input", "actualOutput"]
         }`
```

```json filename="response" showLineNumbers
{"success": true}
```

You **CANNOT** change the `multiturn` value of a metric once it has been created.

## Get Metric(s)

Finally, you can list all metrics in your product as follows (including default ones):

```bash filename="GET - /v1/metrics" showLineNumbers
curl -X GET "https://api.confident-ai.com/v1/metrics" \
     -H "CONFIDENT_API_KEY: <PROJECT-API-KEY>"
```

```json filename="response" showLineNumbers
{
    "success": true,
    "data": {
        "metrics": [{
            "metricId": "TODO",
            "name": "Correctness",
            "criteria": "Determine if the 'actual output' is correct based on the 'input'.",
            "evaluationParams": ["input", "actualOutput"],
            "multiturn": false,
        },
        {
            "metricId": "TODO",
            "name": "Relevancy",
            "criteria": "Determine if the assistant answers are relevant to what the user is asking.",
            "multiturn": true
        }]
    }
}
```