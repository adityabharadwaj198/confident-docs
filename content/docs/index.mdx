---
title: Welcome
---

import { Cards, Callout } from "nextra/components";
import { MessageSquareText, PenLine, Settings, FlaskConical, Telescope, User, Lightbulb, House, ShieldAlert, BookOpen, Folders, Zap, GitBranch } from 'lucide-react'

# Confident AI - The DeepEval Platform

**Confident AI is the cloud platform for DeepEval**, the most widely adopted _open-source_ framework to evaluate LLM applications such as RAG pipielines, agentics, chatbots, or even just an LLM itself.

<details>

<summary>How is Confident AI different from DeepEval?</summary>

While DeepEval is like Pytest for LLM apps, Confident AI is the dashboard UI for DeepEval. 

<Callout type="info">Confident AI created and maintains DeepEval.</Callout>

</details>

<details>

<summary>How does Confident AI work?</summary>

Confident AI enables organizations to iterate on LLM applications by allowing you to pick the best model and improve on different versions of your prompts through extensive [parameter insights](/docs/llm-evaluation/evaluation-features/parameter-insights).

In a nutshell, we do this by running LLM evaluations for both:

1. **In development**, as you're building your app before deploying to production.
2. **In production**, as your app is live and real-time reporting of performance is required.

There are a dozen more features which will be shown in depth later in this documentation that compliments this evaluation workflow as LLM applications can get very complicated very quickly.

</details>

You can get started with **LLM evaluation and observability** in this [5 minutes quickstart guide.](/docs/getting-started/setup)

<Callout type="info">
Confident AI supports evals and tracing for any [LLM use case](/docs/llm-use-cases), including multi-turn ones!
</Callout>

## Features Overview

<Cards>
  <Cards.Card 
    icon={<FlaskConical />} 
    arrow 
    title="LLM Evaluation" 
    href="/llm-evaluation/introduction" 
  />
  <Cards.Card
    arrow
    icon={<GitBranch/>}
    title="LLM Tracing"
    href="/llm-tracing/introduction"
  />
  <Cards.Card 
    arrow 
    icon={<PenLine/>}
    title="Dataset Editor" 
    href="/dataset-editor/introduction" 
  />
  <Cards.Card 
    arrow 
    title="Prompt Studio" 
    href="/prompt-management/introduction" 
    icon={<MessageSquareText/>}
  />
  <Cards.Card
    arrow
    title="Human-in-the-Loop"
    href="/human-in-the-loop/introduction"
    icon={<User/>}
  />
  <Cards.Card 
    arrow 
    title="Red Teaming" 
    href="/llm-red-teaming" 
    icon={<ShieldAlert/>}
  />
</Cards>

## How to Navigate the Docs

This documentation is designed to teach you how to use Confident AI to evaluate your LLM apps with as little fluff as possible. The:

- **Concepts** [section](/docs/concepts/test-cases) covers essential terminology for understanding LLM evaluation - recommended starting point for beginners
- **Quickstart** [section](/docs/getting-started/setup) provides the fundamentals needed to begin using the platform effectively
- **Data Handling** [page](/docs/data-handling) explains data organization, privacy controls, and residency options
- **Platform Features** section details the complete suite of Confident AI capabilities:
  - [LLM Evaluations](/docs/llm-evaluation/introduction)
  - [LLM Tracing](/docs/llm-tracing/introduction)
  - [Dataset Management](/docs/dataset-editor/introduction)
  - [Prompt Engineering](/docs/prompt-management/introduction)
  - [Human-in-the-Loop](/human-in-the-loop/introduction)

<Callout>
  Each individual platform feature page includes either a code and/or video
  summary that you can follow along.
</Callout>

There will be numerous places throughout this documentation where we will reference DeepEval's documentation, especially for running evaluations and customizing metrics. This is **not a mistake**, and everything you see on DeepEval's documentation can be applied directly to Confident AI.

For those interested in using only our open-source **DeepEval** LLM evaluation framework without Confident AI, please visit [DeepEval's documentation](https://deepeval.com).

## FAQs

### How is this different from DeepEval?

While DeepEval computes the metric results required for data-driven LLM app development, it does not provide the insights required for iteration.

[Click here](/docs/why-confident-ai#deepeval-vs-confident-ai) for a more comprehensive comparison.

### What LLM use cases are supported?

All types of LLM use cases are supported, including summarization, Text-SQL, custom support chatbots, internal RAG QAs, conversational agents, etc.

These use cases can be of any system, including RAG pipelines, agentic workflows, conversational chatbots, or just a combination of everything (e.g. RAG chatbots, agentic RAG).

Confident AI has tailored metrics and platform capabilities for different types of LLM applications, and it is extremely important to adjust your evaluation strategy depending on your LLM use case. You can read more on the different types of use cases on [this page.](/docs/llm-use-cases)

### What about complex agentic systems?

Complex agentic systems are definitely supported on Confident AI through [LLM tracing.](/docs/llm-tracing/introduction) One thing to note though is that it is extremely important to decide carefully on what to (not) evaluate in a complex LLM agentic workflow, since trying to evaluate everything means you're actually evaluating nothing.

### Is Confident AI enterprise ready?

Yes, Confident AI offers SSO, data segregation for teams, user roles and permissions (with customizations available), and well as the ability to self-host in your cloud premises.

### What about HIPAA compliance?

We're proudly HIPAA compliant and are willing to sign BAAs with customers on the [Premium subscription plan or above.](https://confident-ai.com/pricing).

### Can I self-host Confident AI?

Yes, while most users are using the SaaS offering, your organization can deploy Confident AI in your cloud premises (e.g. AWS, Azure, GCP, etc.) through a dockerized manner, which includes integrations with your existing identify providers (e.g. Azure AD, Ping, Okta, etc.) of choice for authentication into Confident AI platform. In our experience, this process takes 1-2 weeks max.

### What is the pricing?

No credit card upfront is required, and we offer transparent pricing with 4 different tiers which includes a generous free tier. You can view the [full pricing here.](https://confident-ai.com/pricing)

We try to make it sure that you only pay for something once you have had the chance to try it out. If you don't think this is the case, please email support@confident-ai.com and we will make things more generous.
